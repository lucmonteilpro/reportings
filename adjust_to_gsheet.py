#!/usr/bin/env python3
"""
ADJUST ‚Üí GOOGLE SHEETS PIPELINE
Script standalone pour Sharper Media

Auteur: Refactoris√© pour reprise en main
Date: Novembre 2025
"""

import pandas as pd
import requests
import io
from datetime import datetime, timedelta
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request
from googleapiclient.discovery import build
import gspread
from gspread_dataframe import set_with_dataframe
import os
import pickle
import json

# =============================================================================
# CONFIGURATION
# =============================================================================

ADJUST_API_TOKEN = "KmP1b4iXsW6YSWJxN43g"  # ‚úÖ Token SA BFORBANK qui fonctionne

# Scopes pour Google Sheets
SCOPES = ['https://www.googleapis.com/auth/spreadsheets']

# Configuration SA BFORBANK / WEBANK iOS
BFORBANK_CONFIG = {
    "client": "SA BFORBANK Webank iOS",
    "app_token": "30kmesrwq3nk",  # ‚úÖ App Token Webank iOS
    "adjust_account_id": "29151",  # ‚úÖ Account ID SA BFORBANK - OBLIGATOIRE
    "sheet_id": "1ytoAiVBYn2QkqbiAAVnDicJCbjQLBM2aRZiTPo-dH8k",  # ‚úÖ Google Sheet
    "sheet_name": "raw_ios",  # ‚úÖ Nom de l'onglet
    "start_date": "2025-01-01",
    "custom_cpi": {},  # Pas de custom CPI - pas de cost disponible
    "agg_columns": [
        "Day (date)",
        "Country",
        "Network (attribution)",
        "Campaign (attribution)",
        "Adgroup (attribution)",
        "Creative (attribution)"
    ],
    "group_by_most_spending_campaign": False,
    "compute_ctr": False
}

# Configuration Lalalab Client Report iOS (pour plus tard)
LALALAB_IOS_CONFIG = {
    "client": "Lalalab Client Report ios",
    "app_token": "vmu6fbf5yprt",  # ‚úÖ App Token confirm√© depuis Adjust Dashboard
    "sheet_id": "16xYLvkEsLsLLMN6gCXrgEg7ruPC50U9gsFy32ePBVb4",
    "sheet_name": "ios",
    "start_date": "2025-01-01",
    "custom_cpi": {
        "France": 7.0,
        "Germany": 5.0
    },
    "agg_columns": [
        "App",
        "Month (date)",
        "Week (date)",
        "Day (date)",
        "Network (attribution)",
        "Country",
        "Campaign (attribution)",
        "Adgroup (attribution)",
        "Creative (attribution)"
    ],
    "group_by_most_spending_campaign": False,
    "compute_ctr": False
}


# =============================================================================
# FONCTIONS GOOGLE SHEETS AUTH
# =============================================================================

def get_google_creds():
    """
    Authentification Google.
    Essaie d'abord le Service Account, sinon OAuth.
    """
    creds = None
    
    # Option 1: Service Account (recommand√© - c'est ce que ton tech utilise)
    service_account_file = 'service_account.json'
    if os.path.exists(service_account_file):
        from google.oauth2.service_account import Credentials as ServiceCredentials
        creds = ServiceCredentials.from_service_account_file(
            service_account_file,
            scopes=SCOPES
        )
        print("‚úÖ Auth via Service Account")
        return creds
    
    # Option 2: OAuth (fallback)
    token_file = 'token.pickle'
    
    # V√©rifie si on a d√©j√† des credentials sauvegard√©s
    if os.path.exists(token_file):
        with open(token_file, 'rb') as token:
            creds = pickle.load(token)
    
    # Si pas de credentials valides, on fait l'auth
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            # Tu dois avoir un fichier credentials.json (voir README)
            if not os.path.exists('credentials.json'):
                print("‚ùå ERREUR: Aucun fichier d'authentification trouv√©!")
                print("   Place soit 'service_account.json' (recommand√©)")
                print("   soit 'credentials.json' (OAuth) dans ce dossier.")
                print("   Voir le README pour plus de d√©tails.")
                return None
            
            flow = InstalledAppFlow.from_client_secrets_file('credentials.json', SCOPES)
            creds = flow.run_local_server(port=0)
        
        # Sauvegarde pour la prochaine fois
        with open(token_file, 'wb') as token:
            pickle.dump(creds, token)
    
    print("‚úÖ Auth via OAuth")
    return creds


def get_gspread_client():
    """Retourne un client gspread authentifi√©."""
    creds = get_google_creds()
    if creds is None:
        return None
    return gspread.authorize(creds)


# =============================================================================
# FONCTIONS ADJUST
# =============================================================================

def pull_from_adjust(
    app_token: str,
    begin_date: str,
    end_date: str,
    adjust_account_id: str = None,
    dimensions: str = "day,country,network,campaign,creative,adgroup",
    metrics: str = "installs,clicks,impressions"  # ‚úÖ Seulement les m√©triques auxquelles tu as acc√®s
) -> pd.DataFrame:
    """
    Pull les donn√©es depuis l'API Adjust.
    
    Args:
        app_token: Token de l'app Adjust (ex: "30kmesrwq3nk")
        begin_date: Date de d√©but (format YYYY-MM-DD)
        end_date: Date de fin (format YYYY-MM-DD)
        adjust_account_id: ID du compte Adjust (REQUIS pour certains comptes)
        dimensions: Dimensions √† r√©cup√©rer
        metrics: M√©triques √† r√©cup√©rer
    
    Returns:
        DataFrame avec les donn√©es Adjust
    """
    print(f"üì• Pull Adjust: {begin_date} ‚Üí {end_date}")
    
    params = {
        "date_period": f"{begin_date}:{end_date}",
        "dimensions": dimensions,
        "metrics": metrics,
        "readable_names": True,
        "utc_offset": "+02:00",
        "attribution_type": "all",
        "currency": "EUR",
        "app_token__in": app_token
    }
    
    # CRITIQUE : Ajouter l'account ID si fourni
    if adjust_account_id:
        params['adjust_account_id'] = adjust_account_id
        print(f"   Account ID: {adjust_account_id}")
    
    headers = {
        "Authorization": f"Bearer {ADJUST_API_TOKEN}"
    }
    
    endpoint = "https://automate.adjust.com/reports-service/csv_report"
    
    response = requests.get(endpoint, headers=headers, params=params)
    
    if response.status_code == 200:
        print("‚úÖ Donn√©es r√©cup√©r√©es avec succ√®s")
        df = pd.read_csv(io.StringIO(response.text))
        df = df.sort_values('Day (date)')
        print(f"   {len(df)} lignes r√©cup√©r√©es")
        return df
    else:
        print(f"‚ùå Erreur API: {response.status_code}")
        print(response.text)
        raise ValueError(f"Failed to retrieve data: {response.status_code}")


# =============================================================================
# FONCTIONS DE TRANSFORMATION
# =============================================================================

def transform_data(df: pd.DataFrame, config: dict) -> pd.DataFrame:
    """
    Applique les transformations sur les donn√©es.
    
    BUGS FIXES:
    - Colonnes revenue ajout√©es √† l'exclusion du groupby
    - Filtre installs > 0 corrig√© pour tous les clients Lalalab
    """
    print("üîÑ Transformation des donn√©es...")
    
    tmp = df.copy()
    client = config["client"]
    
    # Filtre sur Network = Sharper
    if "Network (attribution)" in tmp.columns:
        tmp = tmp[tmp["Network (attribution)"] == "Sharper"]
        print(f"   Filtr√© sur Sharper: {len(tmp)} lignes")
    
    # Filtre date de d√©but
    if config.get("start_date"):
        tmp = tmp[pd.to_datetime(tmp["Day (date)"]) >= pd.to_datetime(config["start_date"])]
        print(f"   Filtr√© depuis {config['start_date']}: {len(tmp)} lignes")
    
    # =========================================================================
    # BUG FIX #1: Filtre installs > 0
    # Le code original excluait seulement "Lalalab" exact, pas les variantes
    # =========================================================================
    CLIENTS_SANS_FILTRE_INSTALLS = [
        "Showroomprive.com - Ventes priv√©es",
        "Lalalab",
        "Lalalab Android", 
        "Lalalab Client Report Android",
        "Lalalab Client Report ios",
        "Bforbank"
    ]
    
    if client not in CLIENTS_SANS_FILTRE_INSTALLS:
        before_count = len(tmp)
        tmp = tmp[tmp["Installs"] > 0]
        print(f"   Filtre installs > 0: {before_count} ‚Üí {len(tmp)} lignes")
    else:
        print(f"   ‚ö†Ô∏è  Pas de filtre installs > 0 pour {client}")
        tmp["Impressions"] = tmp["Impressions"].fillna(0)
    
    # =========================================================================
    # BUG FIX #2: Groupby avec colonnes revenue exclues
    # Le code original n'excluait pas les colonnes revenue du groupby
    # =========================================================================
    if config.get("group_by_most_spending_campaign"):
        print("   Grouping by most spending campaign...")
        # [Code de groupby ici si n√©cessaire]
        pass
    
    # Agr√©gation finale
    if config.get("agg_columns"):
        # Colonnes num√©riques √† sommer (pas √† utiliser comme cl√©s de groupby)
        NUMERIC_COLS_TO_SUM = [
            "Impressions", "Clicks", "Installs",
            "0D All Revenue", "7D All Revenue", "30D All Revenue",
            "all_revenue_total_d0", "all_revenue_total_d7", "all_revenue_total_d30"
        ]
        
        # Colonnes d'agr√©gation pr√©sentes dans le DataFrame
        agg_cols = [c for c in config["agg_columns"] if c in tmp.columns]
        
        # Colonnes num√©riques pr√©sentes
        numeric_cols = [c for c in NUMERIC_COLS_TO_SUM if c in tmp.columns]
        
        print(f"   Agr√©gation sur: {agg_cols}")
        print(f"   Somme de: {numeric_cols}")
        
        # Groupby et somme
        tmp = tmp.groupby(agg_cols, as_index=False)[numeric_cols].sum()
        print(f"   Apr√®s agr√©gation: {len(tmp)} lignes")
    
    return tmp


# =============================================================================
# FONCTION PUSH GOOGLE SHEETS
# =============================================================================

def push_to_gsheet(df: pd.DataFrame, config: dict, gc: gspread.Client) -> str:
    """
    Push les donn√©es vers Google Sheets.
    
    Args:
        df: DataFrame √† pusher
        config: Configuration du client
        gc: Client gspread authentifi√©
    
    Returns:
        URL du sheet
    """
    print(f"üì§ Push vers Google Sheets...")
    
    sheet_id = config["sheet_id"]
    sheet_name = config["sheet_name"]
    
    try:
        wks = gc.open_by_key(sheet_id)
        sheet = wks.worksheet(sheet_name)
        
        # Clear et push toutes les donn√©es (pour Lalalab avec d7/d30 revenue)
        sheet.clear()
        set_with_dataframe(sheet, df)
        
        url = f"https://docs.google.com/spreadsheets/d/{sheet_id}"
        print(f"‚úÖ Push r√©ussi: {url}")
        return url
        
    except Exception as e:
        print(f"‚ùå Erreur push: {e}")
        raise


# =============================================================================
# FONCTION PRINCIPALE
# =============================================================================

def run_pipeline(config: dict, begin_date: str = None, end_date: str = None):
    """
    Ex√©cute le pipeline complet pour un client.
    
    Args:
        config: Configuration du client
        begin_date: Date de d√©but (d√©faut: 1er du mois en cours)
        end_date: Date de fin (d√©faut: aujourd'hui)
    """
    print("=" * 60)
    print(f"üöÄ PIPELINE: {config['client']}")
    print("=" * 60)
    
    # Dates par d√©faut
    if end_date is None:
        end_date = datetime.now().strftime("%Y-%m-%d")
    if begin_date is None:
        begin_date = datetime.now().replace(day=1).strftime("%Y-%m-%d")
    
    print(f"üìÖ P√©riode: {begin_date} ‚Üí {end_date}")
    
    # 1. Pull Adjust
    df = pull_from_adjust(
        app_token=config["app_token"],
        begin_date=begin_date,
        end_date=end_date,
        adjust_account_id=config.get("adjust_account_id")  # Passe l'account ID si pr√©sent dans la config
    )
    
    # 2. Transform
    df = transform_data(df, config)
    
    # 3. Affiche un aper√ßu
    print("\nüìä Aper√ßu des donn√©es:")
    print(df.head(10).to_string())
    
    # Affiche les totaux revenue
    revenue_cols = [c for c in df.columns if 'revenue' in c.lower() or 'Revenue' in c]
    if revenue_cols:
        print("\nüí∞ Totaux Revenue:")
        for col in revenue_cols:
            print(f"   {col}: {df[col].sum():,.2f}‚Ç¨")
    
    # 4. Push to GSheet
    gc = get_gspread_client()
    if gc:
        push_to_gsheet(df, config, gc)
    
    # 5. Export CSV local (pour v√©rification)
    output_file = f"output_{config['client'].replace(' ', '_')}_{end_date}.csv"
    df.to_csv(output_file, index=False)
    print(f"\nüíæ Export local: {output_file}")
    
    return df


# =============================================================================
# MAIN
# =============================================================================

if __name__ == "__main__":
    # =========================================================================
    # CONFIGURATION DES DATES
    # =========================================================================
    # Option 1: Dates automatiques (recommand√© pour le cron)
    # R√©cup√®re du 1er du mois jusqu'√† hier
    from datetime import date, timedelta
    today = date.today()
    begin_date = today.replace(day=1).strftime("%Y-%m-%d")
    end_date = (today - timedelta(days=1)).strftime("%Y-%m-%d")
    
    # Option 2: Dates manuelles (d√©commente pour tester une p√©riode sp√©cifique)
    # begin_date = "2025-11-01"
    # end_date = "2025-11-21"
    
    # =========================================================================
    # EX√âCUTION - BFORBANK
    # =========================================================================
    df = run_pipeline(
        config=BFORBANK_CONFIG,
        begin_date=begin_date,
        end_date=end_date
    )
    
    # Pour lancer Lalalab plus tard, d√©commente ci-dessous:
    # df = run_pipeline(
    #     config=LALALAB_IOS_CONFIG,
    #     begin_date=begin_date,
    #     end_date=end_date
    # )
